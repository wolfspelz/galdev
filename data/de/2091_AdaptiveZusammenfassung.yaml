AssertUtf8: ä
Name: AdaptiveZusammenfassung
Year: 2091
Title: Patent für Adaptive Zusammenfassung 
Short: Filme durchblättern wie ein Buch. 
Summary: KI erzeugt in Echtzeit einen Trailer. Während man durch den Film blättert, wird eine Zusammenfassung als Kurzfilm abgespielt. Wichtige Szenen werden gekürzt. Unwichtige Szenen entfallen. Originalmaterial wird ersetzt durch künstlich erzeugte Kurzclips. 
Headline: "HEADLINE HEADLINE: SUBHEADLINE SUBHEADLINE SUBHEADLINE"
Post: "2091 Patent für Adaptive Zusammenfassung. Filme durchblättern wie ein Buch. KI erzeugt in Echtzeit einen Trailer... Mehr: http://jmp1.de/h2091"
Image: AdaptiveZusammenfassung.jpg
Postimage: AdaptiveZusammenfassung.jpg
Smallimage: AdaptiveZusammenfassung-100x70.jpg
Author: Heiner Wolf
Translation: Heiner Wolf
Tags: [Median, KI]
Topics: [culture]
Text: |
  Dynamische adaptive Zusammenfassung von sequenziellen Medien. Mit anderen Worten: Filme durchblättern wie ein Buch. KI erzeugt in Echtzeit eine Vorschau mit Text und Video. Bei Bedarf auch spoilerfrei. 
  Während man durch den Film blättert, wird eine Zusammenfassung als Kurzfilm abgespielt. Wichtige Szenen werden gekürzt. Unwichtige Szenen entfallen. Originalmaterial wird ersetzt durch künstlich erzeugte Kurzclips. 
  Die Geschwindigkeit kann sogar dynamisch variiert werden. Man kann also durch den Film navigieren und sieht immer eine Kurzfassung der aktuellen Passage, die sich automatisch an die Scollgeschwindigkeit anpasst. Beim traditionellen Blättern durch einen Film wurde bisher zumindest der Ton pausiert und vom Video blieben nur zufällige Einzelbilder übrig. Mit der neuen adaptiven Zusammenfassung wird die Kurzform zum Erlebnis. Egal ob als 10 Minuten Kurzfilm, als 3 Minuten Trailer oder als 10 Sekunden Zusammenfassung. Man bekommt die wesentlichen Inhalte und Stimmungen. Später kommt sogar eine automatische Handlungsverschleierung zur Spoilervermeidung dazu.
  Anfang der Zwanzigerjahre änderte sich das Konsumverhalten bei seriellen Medienformaten. Selbstbestimmter On-Demand Konsum löste die fremdbestimmten Programmmedien ab. Für ein Jahrhundert hatten Sender mit vorgefertigten Programmplänen den Medienkonsum dominiert. Konsumenten konnten einen Sender wählen, mussten dann aber dem fremdbestimmten Ablauf folgen – oder den Sender wechseln. Das änderte sich im frühen 21. Jahrhundert. Streaming über Datennetze ermöglichte eine individuelle Inhaltsauswahl. Die Konsumenten konnten endlich selbst bestimmen, was sie sehen oder hören wollten. Ab 2025 wurden mehr Inhalte gestreamt als gesendet. 
  Konsumenten mussten nun aber selbst auswählen. Ohne Auswahl gab es kein Programm. Gleichzeitig stiegen die Ansprüche. Früher gab man sich mit der Auswahl des Senders zufrieden und nahm das vorgefertigte Programm hin auch wenn es nicht optimal war. In den Zeiten des Streamings musste man selbst ein möglichst gutes Programm finden, für sich und für andere Zuschauer der modernen Kleinfamilie. 
  Hilfe bei der Auswahl der richtigen Inhalte gab es reichlich, von traditionellen Inhaltsangaben und Marketingmaterial ("Trailer") bis zu kuratierten Empfehlungslisten und Spartenkanälen. Dann kamen statistisch generierte individuelle Programmvorschläge und KI-basierte Listen. Aber das sind im Wesentlichen Vorschläge. Auswählen mussten die Konsumenten trotzdem selbst. 
  Für Musik-Streaming funktioniert die automatische statistisch-gestützte Auswahl ähnlicher Stücke sehr gut. Der Streaming-Service lernt die Vorlieben und kann aus unzähligen Musikstücken die Passenden auswählen. 
  Bei Filmen und Filmserien ist es anscheinend viel schwieriger Filme zu finden, die den individuellen Geschmack treffen. Deshalb entwickelt sich die Filmbranche anders als die Musikbranche mit ihren automatischen Playlists. Video unterstützt stattdessen die manuelle Auswahl durch die neue Technik der adaptiven Zusammenfassung. 
  Die Patentbehörden der größten Märkte, in China, Europa und in der amerikanischen Handelsunion, Erteilen eine Gruppe von Patenten für die KI-basierte adaptive Medienzusammenfassung. Die Schutzrechte beziehen sich nicht nur auf die technische Realisierung, sondern auch auf die Inhalte. Automatisch erstellte Zusammenfassungen werden als eigene Werke klassifiziert. Das ist möglich, weil die Zusammenfassungen vollständig künstlich erzeugt werden können, ohne Daten der Originalwerke zu benutzen. Die Zusammenfassungen basieren nur auf den Ideen der Vorlagen, nicht auf Inhalten. Sie benutzen keine der ursprünglichen Video- oder Audio-Daten direkt, sondern nur Beschreibungen der einzelnen Elemente. Auch die Abbildungen von Personen und Designs, vor allem von Medienstars und IP basieren auf frei verfügbaren Daten, die angepasst oder erstellt werden, um dem Stil des Originalwerks zu entsprechen, ohne dessen Daten zu benutzen. 
  Der Weg zur adaptiven Zusammenfassung geht über viele Zwischenschritte und Vorläufertechnologien, angefangen mit Texterkennung und automatisch erzeugten Untertiteln um 2020. Ein wichtiger Beitrag zur Szenenanalyse kommt aus dem Werbebereich mit Objekterkennung und -klassifikation für Werbeoverlays und Produktplatzierung. Dann werden statische, aber immerhin automatisch generierte Handlungszusammenfassungen für Blinde entwickelt. In den 40er Jahren des 21. Jahrhunderts zeigt die Text2video-Forschung brauchbare Ergebnisse, die bald zu automatisierten Verfilmungen von Drehbüchern führen. Sogar AAA-Content kann dann in den 50er Jahren vollständig künstliche KI-generierte Schauspieler benutzen und in den 60er Jahren erreicht auch die komplette Szenengenerierung aus Textbeschreibungen ein hohes Qualitätsniveau. Die Disziplin "KI-basiertes Inhaltsverständnis" hatte in den 30er Jahren erste große Erfolge gezeigt, allerdings nur für Spezialfälle. Dann stagnierte der Fortschritt. Erst der Paradigmenwechsel der späten 60er Jahre vom selbstoptimierenden Deep-Learning zum kontextgestützten rückgekoppelten Lernen in selbstmodifizierenden Clustern führt zu einem qualitativen Sprung beim Inhaltsverständnis. 
  Dann kommt der Crash und mit dem Zusammenbruch der Content-Industrie verschwindet auch der Bedarf für adaptive Zusammenfassung zur Unterstützung der Inhaltsauswahl. Die meisten Menschen müssen sich um Grundbedürfnisse kümmern, um ihr Überleben und das ihrer Familie zu sichern. Ein Überwältigendes Medianangebot ist für lange Zeit kein Thema. Die meisten Netze sind sowieso nicht verfügbar. Diese Phase dauert je nach Region zwischen 10 und 30 Jahren. 
  In einigen Regionen erholt sich die Wirtschaft schon in den späten 80er Jahren. Damit erscheint in den dortigen Netzen auch wieder ein großes Medianangebot, anfangs vor allem pre-Crash Produktionen. Wo die Netze schnell wiederhergestellt werden, kann auch das KI Know-how reaktiviert werden. Hardware und vor allem Rechenleistung braucht etwas länger. In den frühen 90ern potenziert sich das Medienangebot schließlich durch vollständig automatisierte Produktionen, die mittels KI-gestützter Roman-zu-Drehbuch Konvertierung und automatischer Szenenvisualisierung alle textbasierten Romane als Videoinhalte verfügbar machen. Zur Jahrhundertwende erholen sich immer mehr Märkte und sowohl Hardware als auch AIware sind bereit zum Einsatz der adaptiven Zusammenfassung von sequentiellen Medien im großen Stil. Eine Technik basierend auf dem neuen patentierten Responsive Ontology Sequence Assembly Model - ROSAM. 
