AssertUtf8: ä
Name: AdaptiveZusammenfassung
Year: 2090
Title: Patent für Adaptive Zusammenfassung 
ShortTitle: Adaptive Zusammenfassung 
Short: Filme durchblättern wie ein Buch. 
Summary: KI erzeugt in Echtzeit einen Trailer. Während man durch den Film blättert, wird eine Zusammenfassung als Kurzfilm abgespielt. Wichtige Szenen werden gekürzt. Unwichtige Szenen entfallen. Originalmaterial wird ersetzt durch künstlich erzeugte Kurzclips. 
Headline: "HEADLINE HEADLINE: SUBHEADLINE SUBHEADLINE SUBHEADLINE"
Post: "2090 Patent für Adaptive Zusammenfassung. Filme durchblättern wie ein Buch. KI erzeugt in Echtzeit einen Trailer... Mehr: http://jmp1.de/h2090"
Image: AdaptiveZusammenfassung.jpg
Postimage: AdaptiveZusammenfassung.jpg
Smallimage: AdaptiveZusammenfassung-100x70.jpg
Author: Heiner Wolf
Translation: Heiner Wolf
Tags: [_nobook, Medien, KI]
Topics: [culture]
Text: |
  Dynamische adaptive Zusammenfassung von sequenziellen Medien. Mit anderen Worten: Filme durchblättern wie ein Buch. KI erzeugt in Echtzeit eine Vorschau mit Text, Ton und Video. Der Detailgrad wird an die Scrollgeschwindigkeit angepasst. Bei Bedarf auch spoilerfrei. 
  Während man durch den Film blättert, wird eine Zusammenfassung als Kurzfilm abgespielt. Wichtige Szenen werden gekürzt. Unwichtige Szenen entfallen. Originalmaterial wird ersetzt durch künstlich erzeugte Kurzclips. 
  Die Geschwindigkeit kann sogar dynamisch variiert werden. Man kann also durch den Film navigieren und sieht immer eine Kurzfassung der aktuellen Passage, die sich automatisch an die Scrollgeschwindigkeit anpasst. Beim traditionellen Blättern durch einen Film wurde bisher zumindest der Ton pausiert und vom Video blieben nur zufällige Einzelbilder übrig. Mit der neuen adaptiven Zusammenfassung wird die Kurzform zum Erlebnis. Egal ob als 10 Minuten Kurzfilm, als 3 Minuten Trailer oder als 10 Sekunden Zusammenfassung. Man bekommt die wesentlichen Inhalte und Stimmungen. Später kommt sogar eine automatische Handlungsverschleierung zur Spoilervermeidung dazu.
  Anfang der Zwanzigerjahre änderte sich das Konsumverhalten bei seriellen Medienformaten. Selbstbestimmter On-Demand Konsum löste die fremdbestimmten Programmmedien ab. Für ein Jahrhundert hatten Sender mit vorgefertigten Programmplänen die Medienauswahl dominiert. Konsumenten konnten einen Sender wählen, mussten dann aber dem fremdbestimmten Ablauf folgen – oder den Sender wechseln. Das änderte sich im frühen 21. Jahrhundert. Streaming über Datennetze ermöglichte eine individuelle Inhaltsauswahl. Die Konsumenten konnten endlich selbst bestimmen, was sie sehen oder hören wollten. Ab 2025 wurden mehr Inhalte gestreamt als gesendet. 
  Konsumenten mussten nun aber selbst auswählen. Gleichzeitig stiegen die Ansprüche. Früher gab man sich mit der Auswahl des Senders zufrieden und nahm das vorgefertigte Programm hin, auch wenn es nicht optimal war. In den Zeiten des Streamings musste man selbst ein möglichst gutes Programm finden, für sich und für andere Zuschauer der modernen Kleinfamilie. 
  Hilfe bei der Auswahl der richtigen Inhalte gab es reichlich, von traditionellen Inhaltsangaben und Marketingmaterial ("Trailer") bis zu kuratierten Empfehlungslisten und Spartenkanälen. Dann kamen statistisch generierte individuelle Programmvorschläge und KI-basierte Listen. Aber das sind im Wesentlichen Vorschläge. Auswählen mussten die Konsumenten trotzdem selbst. 
  Für Musik-Streaming funktioniert die automatische statistisch-gestützte Auswahl ähnlicher Stücke sehr gut. Der Streaming-Service lernt die Vorlieben und kann aus unzähligen Musikstücken die Passenden auswählen. 
  Bei Filmen und Filmserien ist es anscheinend viel schwieriger Filme zu finden, die den individuellen Geschmack treffen. Deshalb entwickelt sich die Filmbranche anders als die Musikbranche mit ihren automatischen Playlists. Video unterstützt stattdessen die manuelle Auswahl durch die neue Technik der adaptiven Zusammenfassung. 
  Die Patentbehörden der größten Märkte, in China, Europa und in der amerikanischen Handelsunion, erteilen eine Gruppe von Patenten für die KI-basierte adaptive Medienzusammenfassung. Die Schutzrechte beziehen sich nicht nur auf die technische Realisierung, sondern auch auf die Inhalte. Automatisch erstellte Zusammenfassungen werden in Europa und Nordamerika als eigene Werke klassifiziert. Das ist möglich, weil die Zusammenfassungen vollständig künstlich erzeugt werden können, ohne Daten der Originalwerke zu benutzen. Die Zusammenfassungen basieren nur auf den Ideen der Vorlagen, nicht auf Inhalten. Sie benutzen keine der ursprünglichen Video- oder Audio-Daten direkt, sondern nur Beschreibungen der einzelnen Elemente. Auch die Abbildungen von Personen und Designs, vor allem von Medienstars und IP basieren auf frei verfügbaren Daten, die angepasst oder erstellt werden, um dem Stil des Originalwerks zu entsprechen, ohne dessen Daten zu benutzen. 
  Der Weg zur adaptiven Zusammenfassung ging über viele Zwischenschritte und Vorläufertechnologien, angefangen mit Texterkennung und automatisch erzeugten Untertiteln um 2020. Ein wichtiger Beitrag zur Szenenanalyse kam aus dem Werbebereich mit Objekterkennung und -klassifikation für Werbeoverlays und Produktplatzierung. Dann wurden statische, aber immerhin automatisch generierte Handlungszusammenfassungen für Blinde entwickelt. In den 40er Jahren des 21. Jahrhunderts zeigte die Text2video-Forschung brauchbare Ergebnisse, die bald zu automatisierten Verfilmungen von Drehbüchern führte. Sogar AAA-Content konnte dann in den 50er Jahren vollständig künstliche KI-erzeugte Schauspieler benutzen und in den 60er Jahren erreichte auch die komplette Szenengenerierung aus Textbeschreibungen ein hohes Qualitätsniveau. Die Disziplin "KI-basiertes Inhaltsverständnis" hatte in den 30er Jahren erste große Erfolge gezeigt, allerdings nur für Spezialfälle. Dann stagnierte der Fortschritt. Erst der Paradigmenwechsel der 50er Jahre vom selbstoptimierenden Deep-Learning zum kontextgestützten rückgekoppelten Lernen in selbstmodifizierenden Clustern führte zu einem qualitativen Sprung beim Inhaltsverständnis. 
  Dann kam der Crash und mit dem Zusammenbruch der Content-Industrie verschwand auch der Bedarf für adaptive Zusammenfassung zur Unterstützung der Inhaltsauswahl. Die meisten Menschen mussten sich um Grundbedürfnisse kümmern, um ihr Überleben und das ihrer Familie zu sichern. Ein überwältigendes Medianangebot war für lange Zeit kein Thema. Die meisten Netze waren sowieso nicht verfügbar. Diese Phase dauerte je nach Region zwischen 10 und 30 Jahren. 
  In einigen Regionen erholte sich die Wirtschaft schon in den späten 80er Jahren. Damit erschien in den Netzen auch wieder ein großes Medianangebot, anfangs vor allem pre-Crash Produktionen. Mit der Wiederherstellung der Netze wurde auch das KI Know-how reaktiviert. Hardware und vor allem günstige Rechenleistung brauchte etwas länger. In den frühen 90ern potenzierte sich das Medienangebot schließlich durch vollständig automatisierte Produktionen, die mittels KI-gestützter Roman-zu-Drehbuch Konvertierung und automatischer Szenenvisualisierung alle textbasierten Romane als Videoinhalte verfügbar machten. 
  In den 90ern erholt sich die Weltwirtschaft. Sowohl Hardware als auch AIware sind nun bereit zum Einsatz der adaptiven Zusammenfassung von sequentiellen Medien im großen Stil. Eine Technik basierend auf dem neuen patentierten Responsive Ontology Sequence Assembly Model – ROSAM.
  Auch individuell erstellte Varianten sind nun möglich. Neben den klassischen – automatisch erstellten – Produktionen werden vor allem individualisierte Medien konsumiert. Individualisierte Medien sind gezielt auf die Vorlieben einzelner Zuschauer zugeschnitten. Sie orientieren sich meistens an vorgegebenen Storylines und Themen, aber Handlungsdetails, Stil und Nebenhandlungen werden so eingestellt, dass das Produkt genau den individuellen Vorstellungen entspricht. Die Zeiten, in denen man sich an Kleinigkeiten gestört hat, sind vorbei. 
  Dabei geht es vor allem um Filme, sowohl traditionelle passive als auch interaktive Filme bis hin zu Games. Aber natürlich auf um Texte, in Schrift und Ton, wobei die Grenzen zwischen Buch, Hörbuch, animiertem Comic und Film fließend sind. 
  Weil diese individualisierten Inhalte in Echtzeit produziert und dabei interaktiv variiert werden können, sind alle Filme verschieden. Die Ausgestaltung ist abhängig von den Konsumenten, der Zeit und Zufallswerten. Kein Medieninhalt gleicht dem anderen. Die Individualisierung is bald so gut, dass die Konsumenten von – aus ihrer Sicht – "fantastisch guten" Medien überrollt werden. Ein neues Suchtverhalten entsteht: Media FOMO, die Angst einen großartigen Film oder das perfekte Game zu verpassen. Damit einher geht oft das Greedy Media Collector Syndrom (GMCS) bei Leuten, die Exabyte an Medien sammeln, weil "alle so gut sind". Diese Sammelleidenschaft wird dadurch unterstützt, dass Sammler mithilfe der dynamischen adaptiven Zusammenfassung jederzeit einen individuellen Überblick über ihre perfekten individuell erstellten Medien bekommen können. 
  Vor Media FOMO und GMCS kann man sich mit Memefiltern schützen – oder mit der Erkenntnis, dass es schon immer viel mehr gute Inhalte gab als man konsumieren konnte und dass sich eigentlich nichts geändert hat seit den Tagen von Doomscrolling und Videohopping. All diese Medieninhalte sind – egal wie großartig und perfekt – letztlich nicht relevant für das reale Leben.

